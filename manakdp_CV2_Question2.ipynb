{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "manakdp_CV2_Question2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PiyushMankad/TCD-Computer-Vision/blob/master/manakdp_CV2_Question2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uWyLKimYj7C",
        "colab_type": "text"
      },
      "source": [
        "# Image Denoising"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkDGLhRUaMfw",
        "colab_type": "code",
        "outputId": "7959bd51-a258-409e-ca15-f458d96d3543",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojfHuJLQYcx8",
        "colab_type": "code",
        "outputId": "2abc5bf7-2523-472b-900f-07cc6c6d425c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "\n",
        "# run this to test the model\n",
        "\n",
        "import argparse\n",
        "import os, time, datetime\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch\n",
        "from skimage.measure import compare_psnr, compare_ssim\n",
        "from skimage.io import imread, imsave\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--set_dir', default=\"../content/drive/My Drive/Colab Notebooks/data/Test\", type=str, help='directory of test dataset')\n",
        "    parser.add_argument('--set_names', default=['Set68'], help='directory of test dataset')\n",
        "    parser.add_argument('--sigma', default=25, type=int, help='noise level')\n",
        "    parser.add_argument('--model_path', default=\"/content/drive/My Drive/Colab Notebooks/models/model_000.pth \", type=str, help='the model name')\n",
        "    parser.add_argument('--result_dir', default=\"/content/drive/My Drive/Colab Notebooks/results\", type=str, help='directory of test dataset')\n",
        "    parser.add_argument('--save_result', default=True, action='store_true', help='save the denoised image')\n",
        "    return parser.parse_args(args=[])\n",
        "\n",
        "\n",
        "def log(*args, **kwargs):\n",
        "     print(\"\\n\",datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S:\"), *args, **kwargs)\n",
        "\n",
        "\n",
        "def save_result(result, path):\n",
        "    path = path if path.find('.') != -1 else path+'.png'\n",
        "    ext = os.path.splitext(path)[-1]\n",
        "    if ext in ('.txt', '.dlm'):\n",
        "        np.savetxt(path, result, fmt='%2.4f')\n",
        "    else:\n",
        "        imsave(path, np.uint8(np.clip(result*255.0, 0, 255)))\n",
        "\n",
        "\n",
        "def show(x, title=None, cbar=False, figsize=None):\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.imshow(x, interpolation='nearest', cmap='gray')\n",
        "    if title:\n",
        "        plt.title(title)\n",
        "    if cbar:\n",
        "        plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "class DnCNN(nn.Module):\n",
        "\n",
        "    def __init__(self, depth=17, n_channels=64, image_channels=1, use_bnorm=True, kernel_size=3):\n",
        "        super(DnCNN, self).__init__()\n",
        "        kernel_size = 3\n",
        "        padding = 1\n",
        "        layers = []\n",
        "        layers.append(nn.Conv2d(in_channels=image_channels, out_channels=n_channels, kernel_size=kernel_size, padding=padding, bias=True))\n",
        "        layers.append(nn.ReLU(inplace=True))\n",
        "        for _ in range(depth-2):\n",
        "            layers.append(nn.Conv2d(in_channels=n_channels, out_channels=n_channels, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "            layers.append(nn.BatchNorm2d(n_channels))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "        layers.append(nn.Conv2d(in_channels=n_channels, out_channels=image_channels, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "        self.dncnn = nn.Sequential(*layers)\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = x\n",
        "        out = self.dncnn(x)\n",
        "        return y-out\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                init.orthogonal_(m.weight)\n",
        "                print('init weight')\n",
        "                if m.bias is not None:\n",
        "                    init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                init.constant_(m.weight, 1)\n",
        "                init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "def main():  \n",
        "    args = parse_args()\n",
        "    # model = torch.load(args.model_path)\n",
        "    model = torch.load(\"/content/drive/My Drive/Colab Notebooks/models/model_000.pth\")\n",
        "    log('load trained model')\n",
        "\n",
        "    model.eval()  # evaluation mode\n",
        "    print(\"\\n\\n Model evaluated\")\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        model = model.cuda()\n",
        "\n",
        "    if not os.path.exists(args.result_dir):\n",
        "        os.mkdir(args.result_dir)\n",
        "\n",
        "    for set_cur in args.set_names:\n",
        "        # print(\"set_cur\",set_cur)\n",
        "\n",
        "        if not os.path.exists(os.path.join(args.result_dir, set_cur)):\n",
        "            os.mkdir(os.path.join(args.result_dir, set_cur))\n",
        "        psnrs = []\n",
        "        ssims = []\n",
        "\n",
        "        for im in os.listdir(os.path.join(args.set_dir, set_cur)):\n",
        "            if im.endswith(\".jpg\") or im.endswith(\".bmp\") or im.endswith(\".png\"):\n",
        "\n",
        "                x = np.array(imread(os.path.join(args.set_dir, set_cur, im)), dtype=np.float32)/255.0\n",
        "                # print(\"x.shape\",x.shape)\n",
        "                np.random.seed(seed=0)  # for reproducibility\n",
        "                y = x + np.random.normal(0, args.sigma/255.0, x.shape)  #(location, scale, size)# Add Gaussian noise without clipping\n",
        "                y = y.astype(np.float32)\n",
        "                y_ = torch.from_numpy(y).view(1, -1, y.shape[0], y.shape[1])\n",
        "                # print(\"y.shape\",y.shape)\n",
        "\n",
        "                torch.cuda.synchronize()\n",
        "                start_time = time.time()\n",
        "                y_ = y_.cuda()\n",
        "                x_ = model(y_)  # inference\n",
        "                x_ = x_.view(y.shape[0], y.shape[1])\n",
        "                x_ = x_.cpu()\n",
        "                x_ = x_.detach().numpy().astype(np.float32)\n",
        "                torch.cuda.synchronize()\n",
        "                elapsed_time = time.time() - start_time\n",
        "                # print('%10s : %10s : %2.4f second' % (set_cur, im, elapsed_time))\n",
        "\n",
        "                psnr_x_ = compare_psnr(x, x_)\n",
        "                ssim_x_ = compare_ssim(x, x_)\n",
        "                if args.save_result:\n",
        "                    name, ext = os.path.splitext(im)\n",
        "                    #show(np.hstack((y, x_)))  # show the image\n",
        "                    save_result(x_, path=os.path.join(args.result_dir, set_cur, name+'_dncnn'+ext))  # save the denoised image\n",
        "                psnrs.append(psnr_x_)\n",
        "                ssims.append(ssim_x_)\n",
        "        psnr_avg = np.mean(psnrs)\n",
        "        ssim_avg = np.mean(ssims)\n",
        "        psnrs.append(psnr_avg)\n",
        "        ssims.append(ssim_avg)\n",
        "        if args.save_result:\n",
        "            save_result(np.hstack((psnrs, ssims)), path=os.path.join(args.result_dir, set_cur, 'results.txt'))\n",
        "        log('Datset: {0:10s} \\n  PSNR = {1:2.2f}dB, SSIM = {2:1.4f}'.format(set_cur, psnr_avg, ssim_avg))\n",
        "\n",
        "## calling the above function\n",
        "# main()\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:459: UserWarning: Couldn't retrieve source code for container of type DnCNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + container_type.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 2019-11-16 18:43:45: load trained model\n",
            "\n",
            "\n",
            " Model evaluated\n",
            "\n",
            " 2019-11-16 18:44:05: Datset: Set68      \n",
            "  PSNR = 29.18dB, SSIM = 0.9009\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaCX4ux3a7Qh",
        "colab_type": "text"
      },
      "source": [
        "# **Question 2.b**\n",
        "\n",
        "Using the assigned sigma value=36"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRzjr-SPW13t",
        "colab_type": "code",
        "outputId": "a462c8f4-b6c9-446f-b5a7-cd28891fde9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "def using_sigma(sigma,model__path=0):\n",
        "  args = parse_args()\n",
        "  # model = torch.load(args.model_path)\n",
        "  try:\n",
        "    model = torch.load(model__path)\n",
        "  except:\n",
        "    model = torch.load(\"/content/drive/My Drive/Colab Notebooks/models/model_000.pth\")\n",
        "  \n",
        "  log('load trained model')\n",
        "\n",
        "  model.eval()  # evaluation mode\n",
        "  print(\"\\n\\n Model evaluated\")\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "      model = model.cuda()\n",
        "\n",
        "  if not os.path.exists(args.result_dir):\n",
        "      os.mkdir(args.result_dir)\n",
        "      \n",
        "  for set_cur in args.set_names:\n",
        "      # print(\"set_cur\",set_cur)\n",
        "\n",
        "      if not os.path.exists(os.path.join(args.result_dir, set_cur)):\n",
        "          os.mkdir(os.path.join(args.result_dir, set_cur))\n",
        "      psnrs = []\n",
        "      ssims = []\n",
        "\n",
        "      for im in os.listdir(os.path.join(args.set_dir, set_cur)):\n",
        "          if im.endswith(\".jpg\") or im.endswith(\".bmp\") or im.endswith(\".png\"):\n",
        "\n",
        "              x = np.array(imread(os.path.join(args.set_dir, set_cur, im)), dtype=np.float32)/255.0\n",
        "              np.random.seed(seed=0)  # for reproducibility\n",
        "              y = x + np.random.normal(0, sigma/255.0, x.shape)  # Add Gaussian noise without clipping\n",
        "              y = y.astype(np.float32)\n",
        "              y_ = torch.from_numpy(y).view(1, -1, y.shape[0], y.shape[1])\n",
        "\n",
        "              torch.cuda.synchronize()\n",
        "              start_time = time.time()\n",
        "              y_ = y_.cuda()\n",
        "              x_ = model(y_)  # inference\n",
        "              x_ = x_.view(y.shape[0], y.shape[1])\n",
        "              x_ = x_.cpu()\n",
        "              x_ = x_.detach().numpy().astype(np.float32)\n",
        "              torch.cuda.synchronize()\n",
        "              elapsed_time = time.time() - start_time\n",
        "              # print('%10s : %10s : %2.4f second' % (set_cur, im, elapsed_time))\n",
        "\n",
        "              psnr_x_ = compare_psnr(x, x_)\n",
        "              ssim_x_ = compare_ssim(x, x_)\n",
        "              if args.save_result:\n",
        "                  name, ext = os.path.splitext(im)\n",
        "                  #show(np.hstack((y, x_)))  # show the image\n",
        "                  save_result(x_, path=os.path.join(args.result_dir, set_cur, name+'_dncnn'+ext))  # save the denoised image\n",
        "              psnrs.append(psnr_x_)\n",
        "              ssims.append(ssim_x_)\n",
        "      psnr_avg = np.mean(psnrs)\n",
        "      ssim_avg = np.mean(ssims)\n",
        "      psnrs.append(psnr_avg)\n",
        "      ssims.append(ssim_avg)\n",
        "      if args.save_result:\n",
        "          save_result(np.hstack((psnrs, ssims)), path=os.path.join(args.result_dir, set_cur, 'results.txt'))\n",
        "      log('Datset: {0:10s} \\n  PSNR = {1:2.2f}dB, SSIM = {2:1.4f}'.format(set_cur, psnr_avg, ssim_avg))\n",
        "      # print(set_cur, psnr_avg, ssim_avg)\n",
        "\n",
        "sigma = 36\n",
        "using_sigma(sigma)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:459: UserWarning: Couldn't retrieve source code for container of type DnCNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + container_type.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-11-16 19:23:43: load trained model\n",
            "\n",
            "\n",
            " Model evaluated\n",
            "2019-11-16 19:23:47: Datset: Set68      \n",
            "  PSNR = 22.03dB, SSIM = 0.5928\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbIsEnkPbQuF",
        "colab_type": "text"
      },
      "source": [
        "# **Question 2.c**\n",
        "\n",
        "main_train.py\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTep8aksbm8E",
        "colab_type": "code",
        "outputId": "acde0edd-3aaa-4dc0-d723-bcf754743f7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# run this to train the model\n",
        "\n",
        "import argparse\n",
        "import re\n",
        "import os, glob, datetime, time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.modules.loss import _Loss\n",
        "import torch.nn.init as init\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "# import data_generator as dg\n",
        "# from tensorflow.keras.preprocessing.image import ImageDataGenerator as dg\n",
        "# from data_generator import DenoisingDataset\n",
        "\n",
        "\n",
        "\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "patch_size, stride = 40, 10\n",
        "aug_times = 1\n",
        "scales = [1, 0.9, 0.8, 0.7]\n",
        "batch_size = 128\n",
        "\n",
        "\n",
        "class DenoisingDataset(Dataset):\n",
        "    \"\"\"Dataset wrapping tensors.\n",
        "    Arguments:\n",
        "        xs (Tensor): clean image patches\n",
        "        sigma: noise level, e.g., 25\n",
        "    \"\"\"\n",
        "    def __init__(self, xs, sigma):\n",
        "        super(DenoisingDataset, self).__init__()\n",
        "        self.xs = xs\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_x = self.xs[index]\n",
        "        noise = torch.randn(batch_x.size()).mul_(self.sigma/255.0)\n",
        "        batch_y = batch_x + noise\n",
        "        return batch_y, batch_x\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.xs.size(0)\n",
        "\n",
        "\n",
        "def show(x, title=None, cbar=False, figsize=None):\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.imshow(x, interpolation='nearest', cmap='gray')\n",
        "    if title:\n",
        "        plt.title(title)\n",
        "    if cbar:\n",
        "        plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def data_aug(img, mode=0):\n",
        "    # data augmentation\n",
        "    if mode == 0:\n",
        "        return img\n",
        "    elif mode == 1:\n",
        "        return np.flipud(img)\n",
        "    elif mode == 2:\n",
        "        return np.rot90(img)\n",
        "    elif mode == 3:\n",
        "        return np.flipud(np.rot90(img))\n",
        "    elif mode == 4:\n",
        "        return np.rot90(img, k=2)\n",
        "    elif mode == 5:\n",
        "        return np.flipud(np.rot90(img, k=2))\n",
        "    elif mode == 6:\n",
        "        return np.rot90(img, k=3)\n",
        "    elif mode == 7:\n",
        "        return np.flipud(np.rot90(img, k=3))\n",
        "\n",
        "\n",
        "def gen_patches(file_name):\n",
        "    # get multiscale patches from a single image\n",
        "    img = cv2.imread(file_name, 0)  # gray scale\n",
        "    h, w = img.shape\n",
        "    patches = []\n",
        "    for s in scales:\n",
        "        h_scaled, w_scaled = int(h*s), int(w*s)\n",
        "        img_scaled = cv2.resize(img, (w_scaled, h_scaled), interpolation=cv2.INTER_CUBIC)\n",
        "        # extract patches\n",
        "        for i in range(0, h_scaled-patch_size+1, stride):\n",
        "            for j in range(0, w_scaled-patch_size+1, stride):\n",
        "                x = img_scaled[i:i+patch_size, j:j+patch_size]\n",
        "                for k in range(0, aug_times):\n",
        "                    x_aug = data_aug(x, mode=np.random.randint(0, 8))\n",
        "                    patches.append(x_aug)\n",
        "    return patches\n",
        "\n",
        "\n",
        "def datagenerator(data_dir='data/Train400', verbose=False):\n",
        "    # generate clean patches from a dataset\n",
        "    file_list = glob.glob(data_dir+'/*.jpg')  # get name list of all .jpg files\n",
        "    # initrialize\n",
        "    data = []\n",
        "    # generate patches\n",
        "    for i in range(len(file_list)):\n",
        "        patches = gen_patches(file_list[i])\n",
        "        for patch in patches:    \n",
        "            data.append(patch)\n",
        "        if verbose:\n",
        "            print(str(i+1) + '/' + str(len(file_list)) + ' is done')\n",
        "    data = np.array(data, dtype='uint8')\n",
        "    data = np.expand_dims(data, axis=3)\n",
        "    discard_n = len(data)-len(data)//batch_size*batch_size  # because of batch namalization\n",
        "    data = np.delete(data, range(discard_n), axis=0)\n",
        "    print('training data finished')\n",
        "    return data\n",
        "\n",
        "'''\n",
        "if __name__ == '__main__': \n",
        "\n",
        "    data = datagenerator(data_dir='data/Train400')\n",
        "     \n",
        "'''\n",
        "\n",
        "# Params\n",
        "parser = argparse.ArgumentParser(description='PyTorch DnCNN')\n",
        "parser.add_argument('--batch_size', default=128, type=int, help='batch size')\n",
        "parser.add_argument('--train_data', default=\"/content/drive/My Drive/Colab Notebooks/data/Train400\", type=str, help='path of train data')\n",
        "parser.add_argument('--sigma', default=36, type=int, help='noise level')\n",
        "parser.add_argument('--epochs', default=1, type=int, help='number of train epochs')\n",
        "parser.add_argument('--lr', default=0.0001, type=float, help='initial learning rate for Adam')\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "batch_size = args.batch_size\n",
        "cuda = torch.cuda.is_available()\n",
        "n_epochs = args.epochs\n",
        "sigma = args.sigma\n",
        "\n",
        "\n",
        "save_dir = 'models'\n",
        "\n",
        "if not os.path.exists(save_dir):\n",
        "    os.mkdir(save_dir)\n",
        "\n",
        "\n",
        "class DnCNN(nn.Module):\n",
        "    def __init__(self, depth=17, n_channels=64, image_channels=1, use_bnorm=True, kernel_size=3):\n",
        "        super(DnCNN, self).__init__()\n",
        "        kernel_size = 3\n",
        "        padding = 1\n",
        "        layers = []\n",
        "\n",
        "        layers.append(nn.Conv2d(in_channels=image_channels, out_channels=n_channels, kernel_size=kernel_size, padding=padding, bias=True))\n",
        "        layers.append(nn.ReLU(inplace=True))\n",
        "        for _ in range(depth-2):\n",
        "            layers.append(nn.Conv2d(in_channels=n_channels, out_channels=n_channels, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "            layers.append(nn.BatchNorm2d(n_channels))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "        layers.append(nn.Conv2d(in_channels=n_channels, out_channels=image_channels, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "        self.dncnn = nn.Sequential(*layers)\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = x\n",
        "        out = self.dncnn(x)\n",
        "        return y-out\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                init.orthogonal_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                init.constant_(m.weight, 1)\n",
        "                init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "class sum_squared_error(_Loss):\n",
        "    \"\"\"\n",
        "    Definition: sum_squared_error = 1/2 * nn.MSELoss(reduction = 'sum')\n",
        "    The backward is defined as: input-target\n",
        "    \"\"\"\n",
        "    def __init__(self, size_average=None, reduce=None, reduction='sum'):\n",
        "        super(sum_squared_error, self).__init__(size_average, reduce, reduction)\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        return torch.nn.functional.mse_loss(input, target, size_average=None, reduce=None, reduction='sum').div_(2)\n",
        "\n",
        "\n",
        "def findLastCheckpoint(save_dir):\n",
        "    file_list = glob.glob(os.path.join(save_dir, 'model_*.pth'))\n",
        "    if file_list:\n",
        "        epochs_exist = []\n",
        "        for file_ in file_list:\n",
        "            result = re.findall(\".*model_(.*).pth.*\", file_)\n",
        "            epochs_exist.append(int(result[0]))\n",
        "        initial_epoch = max(epochs_exist)\n",
        "    else:\n",
        "        initial_epoch = 0\n",
        "    return initial_epoch\n",
        "\n",
        "\n",
        "def log(*args, **kwargs):\n",
        "     print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S:\"), *args, **kwargs)\n",
        "\n",
        "\n",
        "def main2():\n",
        "    # model selection\n",
        "    print('===> Building model')\n",
        "    model = DnCNN()\n",
        "\n",
        "    \n",
        "    initial_epoch = findLastCheckpoint(save_dir=save_dir)  # load the last model in matconvnet style\n",
        "    if initial_epoch > 0 or os.path.isfile(os.path.join(save_dir, 'model_%03d.pth' % initial_epoch)):\n",
        "        print('resuming by loading epoch %03d' % initial_epoch)\n",
        "        model = torch.load(os.path.join(save_dir, 'model_%03d.pth' % initial_epoch))\n",
        "    model.train()\n",
        "    criterion = sum_squared_error()\n",
        "    if cuda:\n",
        "        model = model.cuda()\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "    scheduler = MultiStepLR(optimizer, milestones=[15], gamma=0.1)  # learning rates\n",
        "    for epoch in range(initial_epoch, n_epochs):\n",
        "\n",
        "        scheduler.step(epoch)  # step to the learning rate in this epcoh\n",
        "        xs = datagenerator(data_dir=\"/content/drive/My Drive/Colab Notebooks/data/Train400\")\n",
        "        xs = xs.astype('float32')/255.0\n",
        "        print(\"xs.shape\",xs.shape,type(xs))\n",
        "\n",
        "        xs = torch.from_numpy(xs.transpose((0, 3, 1, 2)))  # tensor of the clean patches, NxCxHxW\n",
        "        DDataset = DenoisingDataset(xs, sigma)\n",
        "        DLoader = DataLoader(dataset=DDataset, num_workers=0, drop_last=True, batch_size=batch_size, shuffle=True)\n",
        "        epoch_loss = 0\n",
        "        start_time = time.time()\n",
        "        print(\"DLoader\",DLoader)\n",
        "\n",
        "        for n_count, batch_yx in enumerate(DLoader):\n",
        "            optimizer.zero_grad()\n",
        "            if cuda:\n",
        "                batch_x, batch_y = batch_yx[1].cuda(), batch_yx[0].cuda()\n",
        "            else:\n",
        "                batch_x, batch_y = batch_yx[1], batch_yx[0]\n",
        "            loss = criterion(model(batch_y), batch_x)\n",
        "            epoch_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if n_count % 100 == 0:\n",
        "                print('%4d %4d / %4d loss = %2.4f' % (epoch+1, n_count, xs.size(0)//batch_size, loss.item()/batch_size))\n",
        "        elapsed_time = time.time() - start_time\n",
        "\n",
        "        log('epcoh = %4d , loss = %4.4f , time = %4.2f s' % (epoch+1, epoch_loss/n_count, elapsed_time))\n",
        "        np.savetxt('train_result.txt', np.hstack((epoch+1, epoch_loss/n_count, elapsed_time)), fmt='%2.4f')\n",
        "        torch.save(model, os.path.join(save_dir, 'new_model_%03d.pth' % (epoch+1)))\n",
        "if __name__ == '__main__':\n",
        "  # main2()\n",
        "  pass\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===> Building model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "training data finished\n",
            "xs.shape (1457920, 40, 40, 1) <class 'numpy.ndarray'>\n",
            "DLoader <torch.utils.data.dataloader.DataLoader object at 0x7fd40c714e48>\n",
            "   1    0 / 11390 loss = 285.9153\n",
            "   1  100 / 11390 loss = 15.4339\n",
            "   1  200 / 11390 loss = 11.1277\n",
            "   1  300 / 11390 loss = 8.3642\n",
            "   1  400 / 11390 loss = 7.0779\n",
            "   1  500 / 11390 loss = 6.3542\n",
            "   1  600 / 11390 loss = 5.5820\n",
            "   1  700 / 11390 loss = 5.0422\n",
            "   1  800 / 11390 loss = 4.9476\n",
            "   1  900 / 11390 loss = 4.8154\n",
            "   1 1000 / 11390 loss = 4.1318\n",
            "   1 1100 / 11390 loss = 4.1258\n",
            "   1 1200 / 11390 loss = 4.2305\n",
            "   1 1300 / 11390 loss = 3.8148\n",
            "   1 1400 / 11390 loss = 3.6761\n",
            "   1 1500 / 11390 loss = 3.8117\n",
            "   1 1600 / 11390 loss = 3.5756\n",
            "   1 1700 / 11390 loss = 3.8710\n",
            "   1 1800 / 11390 loss = 3.2095\n",
            "   1 1900 / 11390 loss = 3.2862\n",
            "   1 2000 / 11390 loss = 3.4172\n",
            "   1 2100 / 11390 loss = 2.8055\n",
            "   1 2200 / 11390 loss = 2.8483\n",
            "   1 2300 / 11390 loss = 2.8692\n",
            "   1 2400 / 11390 loss = 2.9119\n",
            "   1 2500 / 11390 loss = 3.2235\n",
            "   1 2600 / 11390 loss = 2.6195\n",
            "   1 2700 / 11390 loss = 2.7547\n",
            "   1 2800 / 11390 loss = 2.5350\n",
            "   1 2900 / 11390 loss = 2.6899\n",
            "   1 3000 / 11390 loss = 2.3680\n",
            "   1 3100 / 11390 loss = 2.4329\n",
            "   1 3200 / 11390 loss = 2.6647\n",
            "   1 3300 / 11390 loss = 2.3363\n",
            "   1 3400 / 11390 loss = 2.5731\n",
            "   1 3500 / 11390 loss = 2.3213\n",
            "   1 3600 / 11390 loss = 2.7777\n",
            "   1 3700 / 11390 loss = 2.5214\n",
            "   1 3800 / 11390 loss = 2.4920\n",
            "   1 3900 / 11390 loss = 2.6804\n",
            "   1 4000 / 11390 loss = 2.6891\n",
            "   1 4100 / 11390 loss = 2.4972\n",
            "   1 4200 / 11390 loss = 2.4043\n",
            "   1 4300 / 11390 loss = 2.5581\n",
            "   1 4400 / 11390 loss = 2.4228\n",
            "   1 4500 / 11390 loss = 2.3396\n",
            "   1 4600 / 11390 loss = 2.5934\n",
            "   1 4700 / 11390 loss = 2.1753\n",
            "   1 4800 / 11390 loss = 2.1825\n",
            "   1 4900 / 11390 loss = 2.2498\n",
            "   1 5000 / 11390 loss = 2.3832\n",
            "   1 5100 / 11390 loss = 2.4064\n",
            "   1 5200 / 11390 loss = 2.3041\n",
            "   1 5300 / 11390 loss = 2.4362\n",
            "   1 5400 / 11390 loss = 2.0671\n",
            "   1 5500 / 11390 loss = 2.4018\n",
            "   1 5600 / 11390 loss = 2.2047\n",
            "   1 5700 / 11390 loss = 2.3040\n",
            "   1 5800 / 11390 loss = 2.3637\n",
            "   1 5900 / 11390 loss = 2.2527\n",
            "   1 6000 / 11390 loss = 2.2358\n",
            "   1 6100 / 11390 loss = 2.4035\n",
            "   1 6200 / 11390 loss = 2.3469\n",
            "   1 6300 / 11390 loss = 2.3677\n",
            "   1 6400 / 11390 loss = 2.3162\n",
            "   1 6500 / 11390 loss = 2.1494\n",
            "   1 6600 / 11390 loss = 2.4236\n",
            "   1 6700 / 11390 loss = 2.1827\n",
            "   1 6800 / 11390 loss = 2.1706\n",
            "   1 6900 / 11390 loss = 2.2249\n",
            "   1 7000 / 11390 loss = 2.0767\n",
            "   1 7100 / 11390 loss = 2.2168\n",
            "   1 7200 / 11390 loss = 2.4262\n",
            "   1 7300 / 11390 loss = 1.9190\n",
            "   1 7400 / 11390 loss = 1.9551\n",
            "   1 7500 / 11390 loss = 2.0245\n",
            "   1 7600 / 11390 loss = 2.2728\n",
            "   1 7700 / 11390 loss = 2.0658\n",
            "   1 7800 / 11390 loss = 2.1433\n",
            "   1 7900 / 11390 loss = 2.0529\n",
            "   1 8000 / 11390 loss = 2.0842\n",
            "   1 8100 / 11390 loss = 2.0530\n",
            "   1 8200 / 11390 loss = 1.9643\n",
            "   1 8300 / 11390 loss = 2.3056\n",
            "   1 8400 / 11390 loss = 2.1195\n",
            "   1 8500 / 11390 loss = 2.2832\n",
            "   1 8600 / 11390 loss = 1.9847\n",
            "   1 8700 / 11390 loss = 2.1319\n",
            "   1 8800 / 11390 loss = 2.1351\n",
            "   1 8900 / 11390 loss = 2.0897\n",
            "   1 9000 / 11390 loss = 2.2172\n",
            "   1 9100 / 11390 loss = 2.0435\n",
            "   1 9200 / 11390 loss = 2.0034\n",
            "   1 9300 / 11390 loss = 2.1936\n",
            "   1 9400 / 11390 loss = 2.4328\n",
            "   1 9500 / 11390 loss = 2.0581\n",
            "   1 9600 / 11390 loss = 1.9277\n",
            "   1 9700 / 11390 loss = 2.0948\n",
            "   1 9800 / 11390 loss = 1.9743\n",
            "   1 9900 / 11390 loss = 2.0963\n",
            "   1 10000 / 11390 loss = 2.1341\n",
            "   1 10100 / 11390 loss = 2.2197\n",
            "   1 10200 / 11390 loss = 2.2218\n",
            "   1 10300 / 11390 loss = 2.1395\n",
            "   1 10400 / 11390 loss = 1.9647\n",
            "   1 10500 / 11390 loss = 2.3449\n",
            "   1 10600 / 11390 loss = 2.2578\n",
            "   1 10700 / 11390 loss = 2.0691\n",
            "   1 10800 / 11390 loss = 2.0732\n",
            "   1 10900 / 11390 loss = 1.9528\n",
            "   1 11000 / 11390 loss = 2.3680\n",
            "   1 11100 / 11390 loss = 2.1152\n",
            "   1 11200 / 11390 loss = 2.0397\n",
            "   1 11300 / 11390 loss = 2.4563\n",
            "2019-11-16 19:10:17: epcoh =    1 , loss = 408.8339 , time = 1449.69 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DnCNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5K6CBMipXfu",
        "colab_type": "text"
      },
      "source": [
        "# **Question 2.c** (Continuation)\n",
        "\n",
        "**Testing the trained model**\n",
        "\n",
        "Fine-Tuned Model Path: `\"new_model_001.pth\"`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6b6n343pWp-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "eb1c4cf9-1e41-49c7-8a32-6edd93443102"
      },
      "source": [
        "using_sigma(36,\"/content/models/new_model_001.pth\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-11-16 19:23:56: load trained model\n",
            "\n",
            "\n",
            " Model evaluated\n",
            "2019-11-16 19:24:00: Datset: Set68      \n",
            "  PSNR = 26.82dB, SSIM = 0.8425\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXHGvQTIrci9",
        "colab_type": "text"
      },
      "source": [
        "# **Question 2.d**\n",
        "\n",
        "Used sigma = 36 (assigned) in both the denoising image\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "pretrained:  PSNR = 19.98dB, SSIM = 0.7070\n",
        "\n",
        "Fine tuned:  PSNR = 20.18dB, SSIM = 0.5772\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7v8P7cDtleB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "13a535a3-68a2-41c1-891c-8bc361a11fa0"
      },
      "source": [
        "def denoising_image(sigma,model__path,image,imtype):\n",
        "  args = parse_args()\n",
        "  model = torch.load(model__path)\n",
        "  \n",
        "  \n",
        "  model.eval()  # evaluation mode\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "      model = model.cuda()\n",
        "\n",
        "  if not os.path.exists(args.result_dir):\n",
        "      os.mkdir(args.result_dir)\n",
        "      \n",
        "  for set_cur in args.set_names:\n",
        "\n",
        "      if not os.path.exists(os.path.join(args.result_dir, set_cur)):\n",
        "          os.mkdir(os.path.join(args.result_dir, set_cur))\n",
        "      psnrs = []\n",
        "      ssims = []\n",
        "\n",
        "      ## Single image reading\n",
        "      x = np.array(imread(image), dtype=np.float32)/255.0\n",
        "      np.random.seed(seed=0)  # for reproducibility\n",
        "      y = x + np.random.normal(0, sigma/255.0, x.shape)  # Add Gaussian noise without clipping\n",
        "      y = y.astype(np.float32)\n",
        "      y_ = torch.from_numpy(y).view(1, -1, y.shape[0], y.shape[1])\n",
        "\n",
        "      torch.cuda.synchronize()\n",
        "      start_time = time.time()\n",
        "      y_ = y_.cuda()\n",
        "      x_ = model(y_)  # inference\n",
        "      x_ = x_.view(y.shape[0], y.shape[1])\n",
        "      x_ = x_.cpu()\n",
        "      x_ = x_.detach().numpy().astype(np.float32)\n",
        "      torch.cuda.synchronize()\n",
        "      elapsed_time = time.time() - start_time\n",
        "      # print('%10s : %10s : %2.4f second' % (set_cur, im, elapsed_time))\n",
        "\n",
        "      psnr_x_ = compare_psnr(x, x_)\n",
        "      ssim_x_ = compare_ssim(x, x_)\n",
        "      \n",
        "      ## saving your denoised image File\n",
        "      name, ext = os.path.splitext(im)\n",
        "      #show(np.hstack((y, x_)))  # show the image\n",
        "      save_result(x_, path=\"MANKADP@TCD.IE_062_{}.png\".format(imtype)) #MANKADP@TCD.IE_062 # save the denoised image\n",
        "      \n",
        "      psnrs.append(psnr_x_)\n",
        "      ssims.append(ssim_x_)\n",
        "      psnr_avg = np.mean(psnrs)\n",
        "      ssim_avg = np.mean(ssims)\n",
        "\n",
        "      psnrs.append(psnr_avg)\n",
        "      ssims.append(ssim_avg)\n",
        "      if args.save_result:\n",
        "          save_result(np.hstack((psnrs, ssims)), path=os.path.join(args.result_dir, set_cur, 'results.txt'))\n",
        "      log('Datset: {0:10s} \\n  PSNR = {1:2.2f}dB, SSIM = {2:1.4f}'.format(set_cur, psnr_avg, ssim_avg))\n",
        "      print(\"\\n\")\n",
        "\n",
        "\n",
        "print(\"\\nDenoising image on the pretrained model\")\n",
        "denoising_image(36,\"/content/drive/My Drive/Colab Notebooks/models/model_000.pth\",\"/content/drive/My Drive/Colab Notebooks/Additional Files/MANKADP@TCD.IE_062.png\",\"pretrained\")\n",
        "print(\"\\nDenoising image on the Fine-Tuned model\")\n",
        "denoising_image(36,\"/content/models/new_model_001.pth\",\"/content/drive/My Drive/Colab Notebooks/Additional Files/MANKADP@TCD.IE_062.png\",\"clean\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Denoising image on the pretrained model\n",
            "2019-11-16 19:54:42: Datset: Set68      \n",
            "  PSNR = 19.98dB, SSIM = 0.7070\n",
            "\n",
            "\n",
            "\n",
            "Denoising image on the Fine-Tuned model\n",
            "2019-11-16 19:54:42: Datset: Set68      \n",
            "  PSNR = 20.18dB, SSIM = 0.5772\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:459: UserWarning: Couldn't retrieve source code for container of type DnCNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + container_type.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ouDXy4Zy4h1",
        "colab_type": "text"
      },
      "source": [
        "# **Question 2.e**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjMXSGYAy3_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}